{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "filepath:MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "filepath:MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "filepath:MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from mnist import read_data_sets\n",
    "import scipy.misc\n",
    "import os\n",
    "\n",
    "input_data = read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y_ = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用于构建抽象的权重w，偏置b生成函数，其中：\n",
    "    权重参数w用truncated_normal方法生成，这是一个产生正态分布序列的函数\n",
    "    偏置参数b用常数0.1进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用于构建抽象的卷积层和池化层操作，其中：\n",
    "    \n",
    "    conv函数内部调用tensorflow提供的tf.nn.conv2d函数进行卷积计算，具体参数解释：\n",
    "        x为输入tensor\n",
    "        w为卷积核(filter/kernel)\n",
    "        strides参数用于指定卷积核滑动时的步长，如[1,1,1,1]表示卷积核每次在图片上移动一个像素的距离\n",
    "        padding参数用于指定当滑动到最后如果卷积核超出图像范围时的处理方法，same为使用0像素填充超出的部分\n",
    "    \n",
    "    pool函数内部调用tf.nn.max_pool函数进行池化操作，具体参数如下：\n",
    "        x为卷积后产生的“图片”\n",
    "        ksize表示池化操作的范围，如[1,2,2,1]则表示在二维2x2的小方块上进行池化\n",
    "        strides表示池化操作的滑动步长\n",
    "        padding参数意义同tf.nn.conv2d函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "\n",
    "def pool(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用于构建卷积网络流程，具体架构及参数如下：\n",
    "    \n",
    "    网络架构：\n",
    "    卷积层1 - relu激活 - 最大池化 - 卷积层2 - relu激活 - 最大池化\n",
    "    \n",
    "    参数为：\n",
    "    卷积层1：卷积核大小：5*5 由于是灰度图片，通道数为1，人工设定32个卷积核\n",
    "    卷积层2：卷积核大小：5*5 由于第一层卷积产生32个feature_map，通道数为32，人工设定64个卷积核\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_w = weight([5,5,1,32])\n",
    "conv1_b = bias([32])\n",
    "conv1_relu = tf.nn.relu(conv(img,conv1_w) + conv1_b)\n",
    "pool1_pool = pool(conv1_relu) \n",
    "\n",
    "conv2_w = weight([5,5,32,64])\n",
    "conv2_b = bias([64])\n",
    "conv2_relu = tf.nn.relu(conv(pool1_pool,conv2_w) + conv2_b)\n",
    "pool2_pool = pool(conv2_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用于构建全连接层：\n",
    "    \n",
    "    首先将两层卷积之后的feature_map展开成一维，由于经历两次最大池化，因此大小变成原来的1/4，即28/4=7\n",
    "    人工定义神经元个数为1024个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_w = weight([7*7*64,1024])\n",
    "fc1_b = bias([1024])\n",
    "fc1_flat = tf.reshape(pool2_pool,[-1,7*7*64])\n",
    "fc1_relu = tf.nn.relu(tf.matmul(fc1_flat,fc1_w) + fc1_b)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "fc1_drop = tf.nn.dropout(fc1_relu,keep_prob)\n",
    "\n",
    "fc2_w = weight([1024,10])\n",
    "fc2_b = bias([10])\n",
    "y_fc = tf.matmul(fc1_drop,fc2_w) + fc2_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码用于构建训练目标以及优化函数：\n",
    "    \n",
    "    tf.nn.softmax_cross_entropy_with_logits：计算y_和y_fc的交叉熵\n",
    "    tf.train.AdamOptimizer：指明使用Adam优化器，目标是最小化cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-e5313b0a7986>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_fc))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_,1),tf.argmax(y_fc,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0,training accuracy 0.109375\n",
      "step 100,training accuracy 0.921875\n",
      "step 200,training accuracy 0.8125\n",
      "step 300,training accuracy 0.859375\n",
      "step 400,training accuracy 0.828125\n",
      "step 500,training accuracy 0.875\n",
      "step 600,training accuracy 0.96875\n",
      "step 700,training accuracy 0.96875\n",
      "step 800,training accuracy 0.921875\n",
      "step 900,training accuracy 0.953125\n",
      "step 1000,training accuracy 0.96875\n",
      "step 1100,training accuracy 0.984375\n",
      "step 1200,training accuracy 0.96875\n",
      "step 1300,training accuracy 0.984375\n",
      "step 1400,training accuracy 0.96875\n",
      "step 1500,training accuracy 0.984375\n",
      "step 1600,training accuracy 0.984375\n",
      "step 1700,training accuracy 0.984375\n",
      "step 1800,training accuracy 0.96875\n",
      "step 1900,training accuracy 0.984375\n",
      "step 2000,training accuracy 1\n",
      "step 2100,training accuracy 0.96875\n",
      "step 2200,training accuracy 0.984375\n",
      "step 2300,training accuracy 0.96875\n",
      "step 2400,training accuracy 0.984375\n",
      "step 2500,training accuracy 0.984375\n",
      "step 2600,training accuracy 0.984375\n",
      "step 2700,training accuracy 1\n",
      "step 2800,training accuracy 0.984375\n",
      "step 2900,training accuracy 1\n",
      "step 3000,training accuracy 0.984375\n",
      "step 3100,training accuracy 1\n",
      "step 3200,training accuracy 1\n",
      "step 3300,training accuracy 0.96875\n",
      "step 3400,training accuracy 1\n",
      "step 3500,training accuracy 0.984375\n",
      "step 3600,training accuracy 1\n",
      "step 3700,training accuracy 0.953125\n",
      "step 3800,training accuracy 0.984375\n",
      "step 3900,training accuracy 1\n",
      "step 4000,training accuracy 0.96875\n",
      "step 4100,training accuracy 0.984375\n",
      "step 4200,training accuracy 0.984375\n",
      "step 4300,training accuracy 0.984375\n",
      "step 4400,training accuracy 0.96875\n",
      "step 4500,training accuracy 0.984375\n",
      "step 4600,training accuracy 1\n",
      "step 4700,training accuracy 1\n",
      "step 4800,training accuracy 1\n",
      "step 4900,training accuracy 1\n",
      "step 5000,training accuracy 0.984375\n",
      "step 5100,training accuracy 1\n",
      "step 5200,training accuracy 1\n",
      "step 5300,training accuracy 1\n",
      "step 5400,training accuracy 0.984375\n",
      "step 5500,training accuracy 0.953125\n",
      "step 5600,training accuracy 0.984375\n",
      "step 5700,training accuracy 1\n",
      "step 5800,training accuracy 1\n",
      "step 5900,training accuracy 0.984375\n",
      "step 6000,training accuracy 0.984375\n",
      "step 6100,training accuracy 1\n",
      "step 6200,training accuracy 0.984375\n",
      "step 6300,training accuracy 0.984375\n",
      "step 6400,training accuracy 0.984375\n",
      "step 6500,training accuracy 0.984375\n",
      "step 6600,training accuracy 1\n",
      "step 6700,training accuracy 1\n",
      "step 6800,training accuracy 1\n",
      "step 6900,training accuracy 0.984375\n",
      "step 7000,training accuracy 0.984375\n",
      "step 7100,training accuracy 0.984375\n",
      "step 7200,training accuracy 1\n",
      "step 7300,training accuracy 1\n",
      "step 7400,training accuracy 0.984375\n",
      "step 7500,training accuracy 1\n",
      "step 7600,training accuracy 1\n",
      "step 7700,training accuracy 0.984375\n",
      "step 7800,training accuracy 1\n",
      "step 7900,training accuracy 1\n",
      "step 8000,training accuracy 1\n",
      "step 8100,training accuracy 1\n",
      "step 8200,training accuracy 0.984375\n",
      "step 8300,training accuracy 1\n",
      "step 8400,training accuracy 0.984375\n",
      "step 8500,training accuracy 1\n",
      "step 8600,training accuracy 1\n",
      "step 8700,training accuracy 0.984375\n",
      "step 8800,training accuracy 1\n",
      "step 8900,training accuracy 0.984375\n",
      "step 9000,training accuracy 1\n",
      "step 9100,training accuracy 1\n",
      "step 9200,training accuracy 0.984375\n",
      "step 9300,training accuracy 1\n",
      "step 9400,training accuracy 1\n",
      "step 9500,training accuracy 1\n",
      "step 9600,training accuracy 1\n",
      "step 9700,training accuracy 1\n",
      "step 9800,training accuracy 1\n",
      "step 9900,training accuracy 1\n",
      "test accuracy 0.9893\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch = input_data.train.next_batch(64)\n",
    "    if i %100 == 0:\n",
    "        train_acc = accuracy.eval(feed_dict={\n",
    "            x:batch[0],y_:batch[1],keep_prob:1.0})\n",
    "        print(\"step %d,training accuracy %g\" % (i,train_acc))\n",
    "    train_step.run(feed_dict={x:batch[0],y_:batch[1],keep_prob:0.5})\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={x:input_data.test.images,y_:input_data.test.labels,keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
